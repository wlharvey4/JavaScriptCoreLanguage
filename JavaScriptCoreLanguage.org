# -*- mode:org; -*-

#+title:JavaScript Core Language Path
#+subtitle:{{{version}}} {{{date}}}
#+author:Misc999
#+date:2020-12-16 08:15
#+macro:version Version 0.0.1
#+macro:upload-date (eval (current-time-string))
#+bucket:pinecone-forest.com

{{{version}}} {{{date}}}

#+texinfo:@insertcopying


* Introduction
:PROPERTIES:
:unnumbered: t
:source:   PluralSite
:END:
* JavaScript Security Best Practices
  :PROPERTIES:
  :author:   Marcin Hoppe
  :author-url: marcinhoppe.com
  :END:
This course focuses on applications that can be directly attacked over the Web.

Learn how to write more secure JavaScript  code. This course will teach you how
to find,  fix, and prevent  vulnerabilities caused by unique  JavaScript issues
such as prototype pollution, dynamic typing bugs, and code injection attacks.

** Description
Complex Web  applications contain a lot  of JavaScript code. Security  of those
applications depends  on how robust  this code  is. In this  course, JavaScript
Security: Best  Practices, you’ll  learn how  to improve  the security  of your
JavaScript code.

1. First,  you’ll explore  how  exploiting the  dynamic type  system  may lead
   to information disclosure  vulnerabilities.
2. Next,  you’ll discover how  JavaScript dynamic code execution  functions can
   allow attackers to run arbitrary code within your application.
3.  Finally,  you’ll learn  how abusing prototypal  inheritance may  change the
   behavior of your application in unexpected ways.

When you’re finished with this course,  you’ll have the skills and knowledge of
JavaScript  security best  practices needed  to protect  your web  applications
against attackers.

** Course Overview
Hi everyone.  My name is  Marcin Hoppe, and  welcome to my  Pluralsight course,
JavaScript Security:  Best Practices. I  am a software engineer  specialized in
information security.  I am  also a  member of  the Node.js  Ecosystem Security
Working Group and an active contributor to the Open Source Security Foundation.

The   web  is   a   wonderful,  but   dangerous   place,  Attackers,   security
vulnerabilities,  and  data  breaches  are  a fact  of  life  for  many  online
businesses.  JavaScript  has  a  very  special  place  in  the  web  ecosystem.
JavaScript code can  be a target of an  attack, but it can also be  a tool that
hackers use to breach our applications.

In  this course,  we're going  to learn  how to  improve the  security of  your
JavaScript code. We  are going to cover
- the JavaScript  security model,
- dynamic type system  vulnerabilities,
- code injection attacks,
- prototype  pollution, and
- JavaScript security testing tools.

By the end of  this course, you'll know how to find, fix,  and prevent the most
common JavaScript  security bugs.

Before beginning the course, you should be familiar with JavaScript programming
concepts such as
- variables,
- types,
- objects, and
- functions.

I hope you'll  join me on this journey  to learn how to write  more secure code
with the JavaScript Security: Best Practices course, at Pluralsight.
** Code---Wired Brain Coffee App
*** Application Code
#+name:Readme
#+header: :tangle code/02/demos/README.md :mkdirp yes
#+begin_src markdown
# Wired Brain Coffee

This project is a part of a fictional e-commerce application for coffee lovers. It allows users to log in, edit their shipping address, and log out.

It is deliberate vulnerable to demonstrate the following JavaScript security issues:

  - Sensitive data leak caused by a loose comparison bug
  - Code injection vulnerability caused by use of unsafe `eval` function
  - Prototype pollution in the `merge` utility function

# Running the Application

This application requires the Node.js runtime and the npm package manager to run. First, install the required dependencies:

```bash
$ npm install
```

Then, you can start the application by running:

```bash
$ npm start
```

The application listens on `http://localhost:3000`.

# User Credentials

You can use the following user credentials to log in to the application:

| Email                        | Password |
| ---------------------------- | -------- |
| janet@wiredbraincoffee.com   | coldbrew |
| joe@wiredbraincoffee.com     | coldbrew |
| michael@wiredbraincoffee.com | coldbrew |

#+end_src

#+name:Application
#+header: :tangle code/02/demos/app.js :mkdirp yes
#+begin_src js
const express = require('express');
const bodyParser = require('body-parser');

const login = require('./lib/login');
const logout = require('./lib/logout');
const { readProfile, saveProfile } = require('./lib/profile');

const app = express();

app.use(express.static('public'));
app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: true }));

app.post('/login', login);
app.get('/logout', logout);
app.get('/profile', readProfile);
app.post('/profile', saveProfile);

const PORT = 3000;
app.listen(PORT, function () {
  console.log(`http://localhost:${PORT}`);
})

#+end_src

#+name:Application-package.json
#+header: :tangle code/02/demos/package.json :mkdirp yes
#+begin_src js
{
  "name": "js-security",
  "version": "1.0.0",
  "main": "app.js",
  "scripts": {
    "start": "node app.js"
  },
  "author": "Marcin Hoppe <marcin.hoppe@gmail.com>",
  "license": "ISC",
  "dependencies": {
    "body-parser": "^1.19.0",
    "express": "^4.17.1"
  }
}

#+end_src

*** Library Code

**** Login
 #+name:Login
 #+header: :tangle code/02/demos/login.js :mkdirp yes
 #+begin_src js
 const users = require('./users');

 function login(req, res) {
     // Get user credentials
     const { email, password } = req.body;
     // Authenticate the user
     if (authenticate(email, password)) {
         // Mark user session as authenticated
         res.cookie('loggedInUser', email);
         // Get return address
         const returnTo = eval('(' + req.query.returnTo + ')');
         // Redirect to the return address
         res.redirect(returnTo.url);
     } else {
         // HTTP 401 when authentication fails
         res.sendStatus(401);
     }
 }

 function authenticate(email, password) {
     // Try each user
     for (let i = 0; i < users.length; ++i) {
         // If email and password match
         if (users[i].email === email && users[i].password === password) {
             // Authentication successful
             return true;
         }
     }
     // If no user matched, authentication failed
     return false;
 }

 module.exports = login;

 #+end_src

**** Logout
 #+name:Logout
 #+header: :tangle code/02/demos/logout.js :mkdirp yes
 #+begin_src js
 function logout(req, res) {
     // Destroy the session
     res.clearCookie('loggedInUser');
     // Redirect back to the home page
     res.redirect('/index.html');
 }

 module.exports = logout;

 #+end_src

**** Profile
 #+name:Profile
 #+header: :tangle code/02/demos/profile.js :mkdirp yes
 #+begin_src js
 const { filter, getParams, merge } = require('./utils');
 const users = require('./users');

 function readProfile(req, res) {
     // Get search params
     const [field, value] = getParams(req.query, ['field', 'value']);
     // Find user(s)
     const results = filter(users, field, value);
     res.json(results);
 }

 function saveProfile(req, res) {
     // Find user by email
     const [user] = filter(users, 'email', req.body.email);
     // Update the user object if needed
     if (user) {
         // Clone the data coming from request
         const updatedUser = merge({}, req.body);
         Object.assign(user, updatedUser);
     }
     // Respond with the user object
     res.json([user]);
 }

 module.exports = {
     readProfile,
     saveProfile
 };

 #+end_src

**** Users
 #+name:Users
 #+header: :tangle code/02/demos/users.json :mkdirp yes
 #+begin_src js
 [
     {
         "email": "janet@wiredbraincoffee.com",
         "password": "coldbrew",
         "address": "1234 Wired Brain Blvd\r\nAwesome City, MM 55555"
     },
     {
         "email": "joe@wiredbraincoffee.com",
         "password": "coldbrew",
         "address": "1235 Wired Brain Blvd\r\nAwesome City, MM 55555"
     },
     {
         "email": "michael@wiredbraincoffee.com",
         "password": "coldbrew",
         "address": "1236 Wired Brain Blvd\r\nAwesome City, MM 55555"
     }
 ]
 #+end_src

**** Utils
 #+name:Utils
 #+header: :tangle code/02/demos/utils.js :mkdirp yes
 #+begin_src js
 // Return items where a field has specific value
 function filter(items, field, value) {
     const results = [];
     for (let i = 0; i < items.length; ++i) {
         if (items[i][field] == value) {
             results.push(items[i]);
         }
     }
     return results;
 }

 // Retrieve array of parameters from the query string
 function getParams(qs, params) {
     const results = [];
     for (let i = 0; i < params.length; ++i) {
         const value = qs.hasOwnProperty(params[i])
             ? qs[params[i]]
             : null;
         results.push(value);
     }
     return results;
 }

 // Deep merge two objects
 function merge(target, source) {
     for (let prop in source) {
         if (typeof target[prop] === 'object' && typeof source[prop] === 'object') {
             merge(target[prop], source[prop]);
         }
         target[prop] = source[prop];
     }
     return target;
 }

 module.exports = {
     filter,
     getParams,
     merge
 };

 #+end_src

*** Public Code

**** Index
#+name:Index
#+header: :tangle code/02/demos/public/index.html
#+begin_src html
<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="lib/bootstrap/css/bootstrap.min.css">

    <title>Wired Brain Coffee</title>
</head>

<body>
    <h1></h1>
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <a class="navbar-brand" href="index.html">Wired Brain Coffee</a>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto" id="links">
                <li class="nav-item active">
                    <a class="nav-link" href="profile.html">Profile</a>
                </li>
                <li class="nav-item active">
                    <a class="nav-link" href="login.html?returnTo=%7B%22url%22%3A%22index.html%22%7D">Login</a>
                </li>
            </ul>
            <span class="navbar-text" id="loggedInUser">
            </span>
        </div>
    </nav>

    <div class="container">
        <table class="table">
            <thead>
                <tr>
                    <th scope="col">#</th>
                    <th scope="col">Coffee</th>
                    <th scope="col">Action</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <th scope="row">1</th>
                    <td>Typica</td>
                    <td><button type="button" class="btn btn-success">Buy!</button></td>
                </tr>
                <tr>
                    <th scope="row">2</th>
                    <td>Bourbon</td>
                    <td><button type="button" class="btn btn-success">Buy!</button></td>
                </tr>
                <tr>
                    <th scope="row">3</th>
                    <td>Caturra</td>
                    <td><button type="button" class="btn btn-success">Buy!</button></td>
                </tr>
                <tr>
                    <th scope="row">4</th>
                    <td>Pacamara</td>
                    <td><button type="button" class="btn btn-success">Buy!</button></td>
                </tr>
                <tr>
                    <th scope="row">5</th>
                    <td>Geisha</td>
                    <td><button type="button" class="btn btn-success">Buy!</button></td>
                </tr>
            </tbody>
        </table>
    </div>

    <script src="session.js"></script>
    <script src="lib/bootstrap/js/bootstrap.min.js"></script>
</body>

</html>
#+end_src

**** Login
#+name:Login HTML
#+header: :tangle code/02/demos/public/login.html
#+begin_src html
<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="lib/bootstrap/css/bootstrap.min.css">

    <title>Wired Brain Coffee</title>
</head>

<body>
    <h1></h1>
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <a class="navbar-brand" href="index.html">Wired Brain Coffee</a>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto" id="links">
                <li class="nav-item active">
                    <a class="nav-link" href="profile.html">Profile</a>
                </li>
                <li class="nav-item active">
                    <a class="nav-link" href="login.html">Login</a>
                </li>
            </ul>
            <span class="navbar-text" id="loggedInUser">
            </span>
        </div>
    </nav>

    <div class="container">
        <form method="post" action="/login" id="login">
            <div class="form-group">
                <label for="email">Email</label>
                <input type="email" class="form-control" id="email" name="email">
            </div>
            <div class="form-group">
                <label for="password">Password</label>
                <input type="password" class="form-control" id="password" name="password">
            </div>
            <button type="submit" class="btn btn-primary">Login</button>
        </form>
    </div>

    <script src="login.js"></script>
    <script src="session.js"></script>
    <script src="lib/bootstrap/js/bootstrap.min.js"></script>
</body>

</html>
#+end_src

#+name:Login JS
#+header: :tangle code/02/demos/public/login.js
#+begin_src js
// Parse the query string
const queryString = new URLSearchParams(window.location.search);
// Retrieve the return address
const returnTo = queryString.get('returnTo');
// Append it to the login form action URL
const loginFormAction = '/login?returnTo=' + encodeURIComponent(returnTo);
// Update the login form action
document.getElementById('login').action = loginFormAction;

#+end_src

**** Profile
#+name:Profile HTML
#+header: :tangle code/02/demos/public/profile.html
#+begin_src html
<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="lib/bootstrap/css/bootstrap.min.css">

    <title>Wired Brain Coffee</title>
</head>

<body>
    <h1></h1>
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <a class="navbar-brand" href="index.html">Wired Brain Coffee</a>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto" id="links">
                <li class="nav-item active">
                    <a class="nav-link" href="profile.html">Profile</a>
                </li>
                <li class="nav-item active">
                    <a class="nav-link" href="login.html?returnTo=%7B%22url%22%3A%22profile.html%22%7D">Login</a>
                </li>
            </ul>
            <span class="navbar-text" id="loggedInUser">
            </span>
        </div>
    </nav>

    <div class="container">
        <div class="alert alert-danger" role="alert" id="notLoggedIn">
            You need to be <a href="login.html?returnTo=%7B%22url%22%3A%22profile.html%22%7D">logged in</a> to edit the profile!
        </div>
        <form id="profile" class="invisible">
            <div class="form-group">
                <label for="email">Email</label>
                <span class="form-control" id="email" name="email" disabled></span>
            </div>
            <div class="form-group">
                <label for="address">Shipping Address</label>
                <textarea class="form-control" id="address" name="address" rows="3"></textarea>
            </div>
            <button type="button" class="btn btn-primary" id="saveProfile">Save</button>
        </form>
    </div>

    <script src="session.js"></script>
    <script src="profile.js"></script>
    <script src="lib/bootstrap/js/bootstrap.min.js"></script>
</body>

</html>
#+end_src

#+name:Profile JS
#+header: :tangle code/02/demos/public/profile.js
#+begin_src js
function displayProfile(json) {
    const [user] = json;

    // Check if user was found
    if (user) {
        // Display user information on the form
        document.getElementById('email').textContent = user.email;
        document.getElementById('address').textContent = user.address;
        document.getElementById('saveProfile').onclick = saveProfile;
    } else {
        // Display warning
        document.getElementById('email').value = 'Not Found';
    }
}

function saveProfile() {
    // Get user data form the form
    const user = {
        email: document.getElementById('email').textContent,
        address: document.getElementById('address').value
    };
    // Save user profile information
    const promise = fetch('/profile', {
        method: 'POST',
        credentials: 'same-origin',
        headers: {
            'Content-Type': 'application/json'
        },
        body: JSON.stringify(user)
    });

    // Bind user information to the form
    promise
        .then(res => res.json())
        .then(json => displayProfile(json));
}

// Check if the user is logged in (based on email cookie)
if (cookie.startsWith('loggedInUser=')) {
    // Hide the warning banner and show the form
    document.getElementById('notLoggedIn').className = 'invisible';
    document.getElementById('profile').className = 'visible';
    // Get user email from cookie
    const [nameAndValue] = cookie.split(';');
    const email = nameAndValue.slice('loggedInUser='.length);
    // Get user profile information
    const e = encodeURIComponent;
    const url = `/profile?field=${e('email')}&value=${e(email)}`;
    const promise = fetch(url, {
        method: 'GET',
        credentials: 'same-origin'
    });
    // Bind user information to the form
    promise
        .then(res => res.json())
        .then(json => displayProfile(json));
}

#+end_src

**** Session
#+name:Session JS
#+header: :tangle code/02/demos/public/session.js
#+begin_src js
// Check if the user is logged in (based on loggedInUser cookie)
const cookie = decodeURIComponent(document.cookie);
if (cookie.startsWith('loggedInUser=')) {
    // Add logout link
    const links = document.getElementById('links');
    const logoutListItem = links.lastElementChild.cloneNode(true);
    const logoutLink = logoutListItem.firstElementChild;

    logoutLink.text = 'Logout';
    logoutLink.href = '/logout';

    links.appendChild(logoutListItem);

    // Get user email from cookie
    const [nameAndValue] = cookie.split(';');
    const email = nameAndValue.slice('loggedInUser='.length);

    // Display user email
    const loggedInUserField = document.getElementById('loggedInUser');
    loggedInUserField.textContent = email;
}

#+end_src

** Understanding JavaScript Security
*** Introduction
Welcome to the JavaScript Security: Best Practices course, here on Pluralsight.
My name is Marcin Hoppe, and in this course, I will teach you how to write more
secure  and robust  JavaScript code.

The web runs on JavaScript. It is the dominant programming language for writing
browser applications,  and thanks  to the Node.js  runtime, it  is increasingly
common to see it in the back end too. The quality of JavaScript code is crucial
for security  of web applications. This  course, however, is not  about general
web  application  security.  We  will  not address  problems  that  can  affect
applications written in  any programming language.

In this course, we focus on security  issues that are unique to JavaScript, and
they are a result of its dynamic nature.  I will teach

- you how to identify such vulnerabilities,
- how to  fix them, and
- prevent those issues  from creeping into your  code.

In this module, we will focus on  the fundamental role that JavaScript plays in
web application security.  JavaScript can contain vulnerabilities,  but in some
cases it may  even become an attack vector.

There are  two popular environments  for running  JavaScript code, and  both of
them have very different security properties.

1. First, we will take a look at how browsers run JavaScript,
2. and then we will see how  Node.js is different.
3.  Then,  we  will  look  at  language features  that  may  lead  to  security
   vulnerabilities:
   - dynamic typing,
   - dynamic  code  execution, and
   - prototypal inheritance.
4. We  will wrap this  module up  with an example  of a simple  coding mistake,
   literally just  a missing  character, that  leads to  a significant  leak of
   sensitive data.

Information security professionals  are well known for specific  jargon to use.
We will not use it here, but  it is important to understand some basic concepts
of web  security.

- Attacks against web  applications are carried out by people.  You may have an
  image  of a  person in  a  black hoodie  typing  at their  keyboard in  their
  basement, but the reality is much more nuanced.
- Attackers differ based on their capabilities  and motivations. They  can be
  teenagers wanting  to impress their friends, fired  employees seeking
  revenge, as well  as criminals breaking into  applications   for  money.
- Attacks  would   not  be   possible  without vulnerabilities. Vulnerabilities
  are  technical flaws in the  system that allow people with malicious  intent
  to break into our applications  and systems. They can be simple bugs in the
  code, fundamental architecture flaws or configuration mistakes.
- All of them can  lead to data breaches. Those that  usually hit the headlines
  are about  leaking millions and millions  of sensitive data records,  such as
  credit card numbers.
- Data breaches can also involve abusing application functionality,  for
  example  toward their  goods  without paying  or getting  a refund for goods
  that were never purchased  in the first place.
- The most common web application architecture has three tiers,
  1. the browser,
  2. the server, and
  3. the database

JavaScript code can  run both in the  browser and the user's device,  such as a
laptop  or smartphone,  or  on  the server  using  Node.js.
- Vulnerabilities  in server‑side  code may  allow  attackers  to breach
  access  to the  application datastore.
- A successful  attack in a  database may lead to  a data breach  that involves
  many users.
- The impact of  a vulnerability in client‑side code is  typically limited to a
  single user.
- That sounds like good news. Unfortunately, bugs in JavaScript code running in
  a  browser may  allow  attackers to  impersonate the  victim  and to  perform
  actions on their behalf. In this case, the vulnerable JavaScript code becomes
  an attack vector.

*** How A Browser Executes JavaScript Code
JavaScript was created to add interactivity to HTML pages. Web browsers are the
native environment to run JavaScript code.  In fact, JavaScript is the dominant
programming  language in  this space.  When  the user  visits a  web page,  the
browser downloads the HTML  code of that page, as well as  all the other assets
needed  to display  this  page. This  includes CSS  style  sheets, images,  and
JavaScript code.

Browsers  allow users  to visit  multiple pages  at the  same time  in tabs  or
separate browser  windows. This means that  at any given time,  JavaScript code
downloaded from several different sites is executed in the same browser. If one
of those sites is infected or even owned  by the attacker, aren't we at risk of
malicious code  stealing our data  from legitimate sites? Luckily,  browsers do
not  allow for  this, and  every website  executes JavaScript  code in  its own
sandbox  within the  browser.  Code  from one  website  cannot  access data  or
functionality  from  another website.  This  is  one  of the  most  fundamental
security properties of the web.

Some browsers use  very sophisticated sandboxing mechanisms,  like
- running each tab in  a separate operating system  process;
- downloading code over  the Secure HTTP  Protocol; and
- using  Subresource  Integrity, or  SRI  for  short, prevents  attackers  from
  injecting their own malicious code into benign sites.

JavaScript code running in the browser is  restricted in what it can do.
- It has no access to local resources in a  user's computer,
- and this applies to devices such as  webcams or microphones,  the file
  system,  and the local  network.
- The code can use those resources only  using very limited browser APIs.
- This allows the browser  to minimize the attack surface and  ask the user for
  explicit consent for  using those resources.
- Code originating  from different  sites cannot access  each other's  data and
  functionality.  This allows  for even  stronger protection  of data  and code
  execution within the browser.

*** How Node.js Executes JavaScript Code
Node.js is  a runtime environment for  JavaScript based on the  V8 engine built
for the  Google Chrome browser.  The unusual thing about  it is that  it allows
JavaScript  code  to run  outside  of  the browser.  It  has  gained a  lot  of
popularity and has proven  to be a popular tool to  build command line programs
and web  applications.

It is  quite different from the  browser from a security  perspective.

- Browsers download the code, and Node.js loads the code from local files, much
  like other popular  programming  languages.
- The  permissions  model  is  also  different.
- Browsers treat  the code as untrusted  and restrict capabilities it  has
  access to, and Node.js  treats the code with  full trust and grants access
  to all the privileges the operating  system user has access to,  including
  devices, files, and the local  network.
- Attacks based on a security vulnerability  in a browser may affect one victim
  at a time.
- Bugs in Node.js may allow for  full server compromise, potentially leading to
  a serious data breach.

*** JavaScript Security Pitfalls
JavaScript  is a  little  bit of  an unusual  programming  language. Its  rapid
development and massive popularity gave us several language features and coding
patterns  that  may  easily  lead  to  exploitable  security  bugs.

#+texinfo: @heading Dynamic Variables

JavaScript variables  can refer  to objects of  different types.  In statically
typed programming languages, variables can only  store or reference values of a
particular type. An  integer can only store numbers, never  strings or objects.
In  JavaScript, a  variable can  refer  to a  number,  a string  or an  object,
depending on the flow of control. When you  look at the code, you do not always
know  the  types  of  variables.  It  may  lead  to  unintentional  information
disclosure or  other security bugs.

#+texinfo: @heading Invoking the JavaScript Engine

JavaScript programs can  invoke JavaScript engine at runtime. It  sounds like a
really powerful  feature, and it is.  It allows for easy  processing of complex
data formats, such  as mathematical formulas or  implementing applications that
users can  extend with their own  JavaScript code. Unfortunately, this  is also
what  attackers  dream about,  the  ability  to  inject  their code  into  your
application.

#+texinfo: Prototypal Inheritance

JavaScript  has  a  pretty   unusual  inheritance  mechanism.  Most  mainstream
programming languages use classes to express static, hierarchical relationships
between types of objects. In JavaScript,  the same goal is achieved by building
dynamic  relationships between  individual objects.  Each object  has a  parent
object, the prototype it inherits properties  from. If attackers can modify the
objects forming the  prototype chain, they may alter the  behavior of your code
in unforeseen  ways.

#+texinfo: JavaScript Dynamism

The  dynamism of  JavaScript is  powerful  and flexible.  It facilitates  rapid
development and unlocks programmer productivity. If the same dynamism is abused
by attackers, it can lead to security vulnerabilities.

*** Sample Application
Now let's take  a look at the sample application  implemented in JavaScript. It
is a part of an ecommerce system for specialty coffee lovers. In a true startup
fashion, it was built fast and, truth be told, some things might be broken. The
development team  thinks there might be  a few security issues  here and there.

#+texinfo: @heading Login Screen

The first area of concern is the login screen. It looks simple at a glance, but
it has some smarts in how it tracks  where the user was coming from before they
logged in. We  will take a closer  look at that functionality.

#+texinfo: @heading User Profile Management

The  second  area  that  needs   attention  is  user  profile  management.  The
implementation  uses several  programming  idioms that  depend  heavily on  the
dynamic  nature of  JavaScript.  We will  inspect  the code  of  both of  those
features throughout  the course.

#+texinfo: @heading Logging In

We start  on the home screen  of the list of  coffee beans sold by  Wired Brain
Coffee. The first functionality is the login  screen. We type in the email, and
we are  in. Notice  that now  the user's email  is displayed  in the  top right
corner and the Logout button is visible. Now that we are logged in, we can also
access the user profile management screen. It is quite simple, and it allows us
to edit the shipping address. The Email  field is read only.

#+texinfo: @heading Logging Out

Let's log out,  and let's go to  the profile management screen  again. It looks
like we first need to log in before we can edit the profile. Notice that now we
are taken  back to the login  screen that has the  return URL stored in  a JSON
object in  a query string.  User session is  implemented using a  simple cookie
that  contains  user  email.  We  can  easily  display  it  using  the  browser
development tools. Now,  let's take a closer look at  how this functionality is
implemented.

*** Code Walkthrough

The Wired Brain Coffee ecommerce application consists of two components, server
and client.  The back‑end code is  implemented in JavaScript using  Node.js and
the Express framework. The details of  this framework are not relevant for this
course, but it allows  us to easily handle serving JavaScript  code, as well as
CSS and HTML assets.  It also allows us to dynamically  generate and serve JSON
documents. All those files are served by  the server to the browser.

#+texinfo: @heading Server Code

Let's take a look at the server  code.

- The ~app.js~ file configures the Express framework to serve  static files,
  parse JSON documents, and  handle HTML forms.

- The code in ~login.js~ handles the =login= form.
  - It first reads the email and   password from the  form and checks if  they
    match the users  in our database. This is a sample application, so storing
    user information in a flat JSON file is good  enough.
  - If the user credentials are verified, the code sends the cookie back to the
    browser and redirects the user to the  return URL from the JSON object from
    the query string.
  - If the credentials are not verified, the code returns an HTTP 401 code.

- The code in  ~logout.js~ is very simple. It removes  the cookie and redirects
  the user back to the home page.

- ~Profile.js~ has two functions.
  - One of them is responsible for  /reading profile information/ from the JSON
    file based  on some search criteria.  The criteria are sent  in the =field=
    and  =value= query  string parameters.  Then, we  filter the  user database
    based on those criteria. The results are sent back to the browser in a JSON
    file.

  - The function responsible for /saving the profile information/ is a bit more
    complex.
    - First, we  find a user based  on the =Email= field.
    - If the user has  been found, we clone the field from  the request using a
      JavaScript idiom that merges the =request= object with an empty object.
    - Then, we assign all the fields from this copy to the =user= object in our
      =user= database.
    - Then, we return to user profile and JSON file.

- I'm sure  you have noticed  a few helper  functions defined in  ~utils.js~.
  - The ~filter~  function returns those  elements of  the items array  where a
    given field matches  the provided  value.
  - The  ~getParams~ function  retrieves an  array of  values from  the =query=
    string object. The values are retrieved  by names specified in the =params=
    array. The function also gracefully  handles missing values returning null,
    which is a JavaScript value to denote missing data.
  - The= ~merge~  function performs a deep  recursive merge of properties  of the
    source object with the properties of the target object. Using such a function
    with  an  empty object  as  the  target is  a  popular  JavaScript idiom  for
    performing deep copies of objects.

*** Loose Comparison Vulnerability
JavaScript has  a dynamic type  system. It  means that variables  can reference
values of different  types throughout their lifetime. At one  point, a variable
may refer to  a number, and it may  refer to a string later on.  The rules that
describe how  operations are applying  to values  of different types  are quite
complex  and can  lead to  security issues.

When  JavaScript  code attempts  to  perform  an  operation  on two  values  of
different types, it needs to convert them to a common type where that operation
is well  defined. For example,  adding a number to  a string will  convert that
number to a  string, and the addition operation will  become a concatenation of
two  strings.  This may  lead  to  unexpected code  being  called  if types  of
variables  are  not  properly  tracked   and  controlled.

JavaScript has  two comparison operators,  strict, also known as  triple equals
(===), and loose,  known as double equals (==). The  strict comparison operator
compares both the value  and type, so a string can never be  equal to a number.
The  loose  comparison,   when  applied  to  parameters   of  different  types,
automatically converts  the operands to  a common  type to make  the comparison
possible. When using this operator, a string  can, in some cases, be equal to a
number.

Comparing values such as =null= and  =undefined= is another corner case. Strict
comparison  will always  treat those  two values  as different,  but the  loose
comparison will  treat them as  equal. This may  lead to security  checks being
bypassed. If  they use the loose  comparison, variable types are  not enforced.

Another aspect of JavaScript  dynamism is that it used to  be very forgiving of
programming errors. Over time, it  became clear that certain language features,
like giving any function an ability  to define a global variable, are dangerous
for security  and the  correctness of  the code.  Newer versions  of JavaScript
allow the  code to run  in so‑called "strict" mode  that prohibits some  of the
problematic  behaviors. Strict  mode is  enabled  by putting  the "use  strict"
string literal at the  beginning of a script or function,  and it should always
be used when writing  JavaScript code.

Let's get back to the code of the Wired Brain Coffee application. Let's quickly
review all the code files for use  of the loose comparison operator. If we find
it is used in a security check  that operates on untrusted input data, it might
be a security  vulnerability. It looks like the double  equals operator is used
in the ~filter~ utility function and is called from the ~readProfile~ function.
Now let's take a quick look at how to exploit this bug.

*** Exploiting the Vulnerability
We identified a potential vulnerability. Now we  need a way to make use of this
bug  to either  steal  sensitive  data or  abuse  functionality  of our  sample
application.

There are a few ways to make  use of automatic conversions and loose comparison
to invoke an unwanted or unexpected behavior. We can try to use numbers instead
of strings, we  can use arrays where  objects are expected, we  can also remove
properties that get  the JavaScript value =undefined=.

When we have identified input that may potentially lead to an attack, we should
work backwards from the vulnerable code to the  input data to try to find a way
to  deliver it  to the  vulnerable piece  of code.  When we  have that,  we can
inspect  the HTTP  requests  and  responses using  browser  developer tools  or
proxies such  as Fiddler.

The  next step  is to  modify legitimate  requests to  include malicious  data.

Finally, we  send such modified requests  to the application.

Let's see how  we may do this for  the loose comparison we found  in the filter
function. The loose comparison tries to  compare a field of an object, provided
as  an  input  parameter, to  a  specific  value,  also  provided as  an  input
parameter. Both the field and the  value are taken from =request= parameters in
the ~readProfile~ function. If we could trick the filter condition to always be
=true=, we  would be able  to retrieve information about  all the users  in the
database.

- If the  field did not  exist, the  property retrieval, the  bracket notation,
  would return undefined.
- If the value was =null=, the loose comparison would always be true.
- Luckily for  the attacker, it will  be =null= if  it is missing from  the
  query string thanks to  the ~getParams~ function.

Let's see  how we  can do  that.

1. The first  step is  to capture  the legitimate request.
   - Let's open  the browser developer tools and let's  inspect the network traffic.
   - The =request= has a field name and value in the query string.
   - The =response=  contains an array with  a single user object  matching the
     provided  email value.
2. Now, let's  modify the =request=.
   - Let's remove the  value from the query string, and  let's change the field
     name to an invalid value.
   - It's time to send such a modified request to the application.
   - The =response=  now contains information  about all the users.

Our attack has been successful. Now, let's see how to fix it.

*** Fixing the Code
There  are  several  ways  to  fix security  vulnerabilities  coming  from  the
JavaScript dynamic typed system.
- Using strict  mode is a no‑brainer, except for cases where backwards
  compatibility is a concern. All code should run in strict mode.
- Using loose  comparison  can lead  to  strange bugs,  and  when used  in
  security checks it can lead to their bypass. The strict comparison operator,
  or triple  equals (===),  should  be used  instead.
- Object equality can also be checked using the ~Object.is~ method, which works
  almost like triple equals, except for  a few corner cases related to numbers.
- Untrusted input should always be subject  to data type verification. All data
  coming from outside  of the application might have  potentially been tampered
  with by the  attacker and may cause unexpected type  conversions and unwanted
  behavior.

Now, let's fix our vulnerability. The  simplest way to fix the loose comparison
vulnerability is to replace it with  the triple equals operator. Now, let's see
if this stopped the attack.

- Let's send  the malicious request again. We need to remove the value
  parameter and change  the field parameter to an invalid value.
- Now we get  the expected result, an  empty array. The array  is empty because
  the comparison  operator correctly distinguished between  null and undefined.
- If this behavior still  seems a little off to you,  you're right, we're still
  relying on arcane  rules of comparison of =null= and  =undefined= values. The
  input data validation should be a  lot stricter and reject incorrectly formed
  requests.
- Let's add  validation for the field  and value parameters and  return an HTTP
  400 code  to inform  the caller that  the request was  malformed. We  need to
  check if  the type of both  field and value variables  is a string. If  it is
  not, we have to return the error  code and skip the rest of the ~readProfile~
  function.
- Let's send the malicious request again.  Now, the server properly responds to
  a malicious attack. We tightened our  defenses by verifying that all required
  parameters are indeed present and that the types are what we expect

*** Summary
In this module, we covered which JavaScript features may lead to security bugs.

- We have seen  how the dynamic type  system may lead to  disclosure of
  sensitive information.  In the  next two  modules, we  will dive  deep into
  dynamic code execution and prototypal inheritance, and we  will see how these
  features might be exploited.
- We have also  taken a look at  the two most popular  environments for running
  JavaScript code,  and we  have seen  how different they  are from  a security
  perspective.
  - Browsers run  JavaScript in a  secure sandbox, but bugs  may be used  as an
    attack vector.
  - JavaScript code running on Node.js has  all the privileges of the operating
    system  account it  runs under,  and the  bugs may  lead to  a full  server
    compromise.

You will see one such vulnerability in the next module.

** Preventing Code Injection Attacks
** Defending Against Prototype Pollution
** Testing Your Code

* Build Tools
:PROPERTIES:
:appendix: t
:custom_id: build-tools
:END:
** Makefile					:dependencies:env_vars:perl:
:PROPERTIES:
:appendix: t
:dependency1: make
:dependency2.0: AWS User account at https://aws.amazon.com
:dependency2.1: AWS cli v2 in PATH https://docs.aws.amazon.com/cli/index.html
:dependency2.2: See how to Install AWS CLI v2 at https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html
:dependency2.3: aws credentials: access token and secret access token stored in ~/.aws/credentials
:dependency2.4: AWS S3 buckets set up for serving a static web page
:dependency3: GitHub Account with personal access token stored in GITHUB_TOKEN
:dependency4: texinfo @6.7._
:dependency5: Emacs, Org-mode, Babel language 'shell' enabled
:env_var1: SYNC_ORG_TEMPLATE: holds the full path to this Template.org file
:env_var2: GITHUB_TOKEN: holds the GitHub personal access token
:env_var3: EDITOR: must hold a reference to a working emacsclient server
:env_var4: COLORS
:END:

#+pindex:Makefile
#+name:Makefile
#+header: :tangle Makefile
#+begin_src makefile

  ###############################################################################
  ### USER-DEPENDENT VARIABLES
  ### USE ENVIRONMENT VARIABLES WHENEVER POSSIBLE

  # NOTE: All environment variables need to be exported PRIOR to starting the
  # Emacs server as EDITOR in your shell startup files; otherwise, they will not
  # be available to Emacs.
  # When I moved from using Bash to Zsh, I inadvertently changed the order of
  # import, and started the Emacs server before importing, and caused a horrible
  # bug which caused the program to work on one computer but fail on another.

  # The absolute path to this Template file
  TEMPLATE := $(SYNC_ORG_TEMPLATE)


  ### TOOLS & RESOURCES
  # tools is a directory holding tangled scripts, such as cmprpl
  # resources is a directory holding static resources for the project
  # images is a directory holding jpg and png image files
  RESOURCES := resources
  TOOLS	    := $(RESOURCES)/tools
  IMAGES    := $(RESOURCES)/images
  CMPRPL    := $(TOOLS)/cmprpl

  # Use emacsclient as $EDITOR; make sure it is set in a shell startup file and
  # the server has been started.
  EMACS	  := $(EMACS)
  EDITOR  := $(EDITOR)

  # User’s personal GitHub token for authentication to GitHub
  # DO NOT HARD-CODE THIS VALUE
  GITHUB_TOKEN := $(GITHUB_TOKEN)

  # The AWS Command Line Interface (AWS CLI) is an open source tool
  # that enables you to interact with AWS services using commands in
  # your command-line shell.  It must be present on your system.  Run the 'make'
  # command 'install-aws-cli' to install it if you do not have it.  Be sure to
  # run 'aws configure' after installing it.  This will place your AWS
  # credentials into ~/.aws/credentials.
  AWS := aws
  S3  := $(AWS) s3
  CFD := $(AWS) cloudfront

  ### END OF USER-DEPENDENT VARIABLES
  ###############################################################################
  ### MAKE-GENERATED VARIABLES

  ### PROJ AND ORG
  # ORG is the name of this Org file with extension .org
  # PROJ is the project name---the Org file name without extension.

  ### NOTE: there can be only one Org file in the project directory;
  # so far this has not been a problem, but it might be.

  PWD  := $(shell pwd)
  ORG  := $(shell ls *.org)
  PROJ := $(basename $(ORG))

  ### NOTE: S is needed only for the Template file because of the way it is nested
  # one level deep in the Templates GitHub repo, which uses the plural form
  # of Templates, whereas this file uses the singular form, Template.  So when
  # the homepage link is updated, the curl command must be told to use the plural
  # form.	 This is obviously a hack only for my own use and can be removed once
  # I clean up this anomaly.

  ifeq ($(PROJ),$(basename $(notdir $(TEMPLATE))))
  S := s
  endif

  # The AWS S3 bucket to use to store the html source file; it is found at the
  # key #+bucket towards the beginning of the file and should include the appropriate
  # suffix (.com, .net, .org, etc)
  BUCKET       := $(shell $(EDITOR) --eval \
		 '(with-current-buffer (find-file-noselect "$(ORG)") \
		    (save-excursion \
		      (goto-char (point-min)) \
		      (re-search-forward "^\#[+]bucket:\\(.*\\)$$" nil t) \
		      (match-string-no-properties 1)))')
  S3_BUCKET    := s3://$(BUCKET)

  # Buckets set up to serve static web sites from S3 can use either http
  # or https protocols; some  http protocols will automatically redirect
  # to https;  however, some only use  http. I would like  to accomodate
  # both, and  so this code  finds the url's  that are in  my Cloudfront
  # account, which presumably will serve https.  If the url is not here,
  # then this must be set up to serve http instead.
  HTTP_S := $(shell $(CFD) list-distributions | perl -MJSON::PP -e \
	  '$$/=""; \
	   my @urls = (); \
	   my $$json=JSON::PP->new->decode(<STDIN>); \
	   for my $$item ( @{$$json->{"DistributionList"}{"Items"}} ) { \
		  push @urls, @{$$item->{"Aliases"}{"Items"}}; \
	   } \
	  my $$found = grep { /'$(BUCKET)'/ } @urls; \
	  print "http", ($$found ? "s" : "");')

  HTTPS_BUCKET := https://$(BUCKET)

  ### DIR, SRC
  # DIR is the .info name found at '#+texinfo_filename:<DIR>.info' (at
  # the bottom of this file in the export configuration settings)
  # without its extension, used as the INFO filename and the name of the
  # HTML export directory; this code uses the lowercased PROJ name if
  # there is no '#+texinfo_filename'.
  # SRC is HTML directory based upon the DIR name

  #DIR := $(shell $(EDITOR) --eval \
  #	'(with-current-buffer (find-file-noselect "$(ORG)") \
  #		(save-excursion \
  #		(goto-char (point-min)) \
  #		(re-search-forward "^\#[+]\\(?:texinfo_filename\\|TEXINFO_FILENAME\\):\\(.*\\).info$$" nil t) \
  #		(match-string-no-properties 1)))')

  DIR := $(shell sed -E -n "/^\#\+texinfo_filename/s/^.*:(.*)\.info$$/\1/p" $(ORG))
  ifeq ($(DIR),$(EMPTY))
	  DIR := $(shell echo $(PROJ) | tr "[:upper:]" "[:lower:]")
  endif

  SRC := $(DIR)/

  ### VERS: v1.2.34/
  # VERS is the version number of this Org document.
  # When sync is run after the version number has been updated, then VERS
  # picks up the newly-changed value.  VERS used to be staticly imbedded
  # when the Makefile was tangled, but it needs to be dynamic for
  # development.

  # QUERY: should this number be formatted like this, or should it be just the numbers?
  # The reason it includes them is the S3PROJ obtains the name from the S3 bucket, and
  # it includes them.  But it only includes them because I have made it so.  Not a good
  # reason just by itself.  The ending slash is not actually a part of the version, but
  # comes from the way the 'aws2 ls' command returns its values.	So VERS should probably
  # not include the trailing slash, although it doesn’t hurt anything.

  VERS := v$(shell $(EDITOR) --eval \
	  '(with-current-buffer (find-file-noselect "$(ORG)") \
		  (save-excursion \
		    (goto-char (point-min)) \
		    (re-search-forward "^\#[+]\\(?:macro\\|MACRO\\):version Version \\(\\(?:[[:digit:]]+[.]?\\)\\{3\\}\\)") \
		    (match-string-no-properties 1)))')/

  ### AWS
  # PROJ_LIST contains the list of projects currently uploaded to
  # the S3 bucket; each item contains the name of the project and its
  # current version.

  # Created function using elisp instead of the shell.
  # This variable contains an elisp list of strings of the form '("proj1-v1.2.3/" "proj2-v4.5.6/" ...)'
  # However, when it prints to the shell, the quotes are lost.
  # Need to make sure elisp's variable 'exec-path contains the proper $PATH instead of adding to 'exec-path.

  PROJ_LIST := $(shell $(EDITOR) --eval \
	  "(progn \
		  (require (quote seq)) (add-to-list (quote exec-path) (quote \"/usr/local/bin\")) \
		  (seq-map (lambda (s) (replace-regexp-in-string \"^\s+PRE \" \"\" s)) \
			  (seq-filter (lambda (s) (string-match-p (regexp-quote \" PRE \") s)) \
			  (process-lines \"$(AWS)\" \"s3\" \"ls\" \"$(S3_BUCKET)\"))))")

  ### S3PROJ
  # The name of the current project as obtained from S3: 'proj-v1.2.34/'
  # If there is no current project in the S3 bucket, then assign a value equal to
  # the Org project and version instead.  It is set to the project if found, and
  # NO if not found, then updated in the ifeq block below.
  S3PROJ := $(shell $(EDITOR) --eval \
		  '(let ((proj (seq-find (lambda (s) (string-match-p "$(DIR)" s)) (quote $(PROJ_LIST))))) \
		     (or proj (quote NO)))')

  ### PROJINS3
  # is used by make sync; this allows the index.html file to be generated the first
  # time the project is synced.  It is set to NO if this project is not currently in an
  # S3 bucket, and it is set to YES if it is.
  PROJINS3 :=

  ### S3VERS
  # The version of this project currently installed in the S3 bucket: 'v1.2.34/'
  # If there is no current version in the S3 bucket, then assign the version from
  # this Org file instead.
  S3VERS   :=

  # Update S3PROJ, S3VERS, and PROJINS3
  ifeq ($(S3PROJ), NO)
	  S3PROJ := $(DIR)-$(VERS)
	  S3VERS := $(VERS)
	  PROJINS3 := NO
  else
	  S3VERS := $(subst $(DIR)-,,$(S3PROJ))
	  PROJINS3 := YES
  endif

  ### GITHUB
  # USER is the current user's GitHub login name.

  # The user name used to be statically embedded into the Makefile
  # during tangle, but in an effort to make the Makefile dynamically
  # indepedent, dynamic code has replaced the static code.  The code
  # that placed the static name in the Makefile was a 'node' script that
  # ran in a separate Org process during tangle.	An unfortunate fact of
  # 'make' is that 'make' strips the quote marks from the string
  # obtained from the 'curl' command when the 'make shell' command
  # returns the string.	 This makes the string malformed JSON and
  # unparsable by most JSON parsers, including 'node’.	However,
  # 'perl'’s core module JSON::PP (but not JSON::XS) has facilities to
  # parse very malformed JSON strings.	Therefore, this dynamic code
  # uses 'perl' and the core module JSON::PP to parse the 'curl' string
  # into a 'perl' JSON object which can return the login name.	This
  # code should work with any version of 'perl' without having to
  # install any modules.

  USER	:= $(shell \
	    curl -sH "Authorization: token $(GITHUB_TOKEN)" https://api.github.com/user \
	    | \
	    perl -MJSON::PP -e \
		'$$/ = ""; \
		 my $$json = JSON::PP->new->loose->allow_barekey->decode(<STDIN>); \
		 print $$json->{login};' \
	    )
  SAVE		:= resources

  ### TEXINFO
  TEXI		:= $(PROJ).texi
  INFO		:= $(DIR).info
  INFOTN	:= $(shell $(EDITOR) --eval "(file-truename \"$(INFO)\")")
  PDF		:= $(PROJ).pdf
  INDEX		:= index.html
  HTML		:= $(DIR)/$(INDEX)
  DIR_OLD	:= $(DIR)-old

  ### AWS S3
  DST_OLD	:= $(S3_BUCKET)/$(S3PROJ)
  DST_NEW	:= $(S3_BUCKET)/$(DIR)-$(VERS)
  EXCL_INCL	:= --exclude "*" --include "*.html"
  INCL_IMAGES	:= --exclude "*" --include "*.jpg" --include "*.png"
  GRANTS	:= --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers
  S3SYNC	:= $(S3) sync --delete $(EXCL_INCL) $(SRC) $(DST_OLD) $(GRANTS)
  S3MOVE	:= $(S3) mv --recursive $(DST_OLD) $(DST_NEW) $(GRANTS)
  S3COPY	:= $(S3) cp $(INDEX) $(S3_BUCKET) $(GRANTS)
  S3REMOVE	:= $(S3) rm $(S3_BUCKET)/$(S3PROJ) --recursive
  S3IMAGESYNC	:= $(S3) sync $(INCL_IMAGES) $(IMAGES) $(S3_BUCKET)/$(IMAGES) $(GRANTS)

  ###############################################################################

  default: check texi info html pdf

  PHONY: default all check values boot \
	    texi info html pdf \
	    open-org open-texi open-html open-pdf \
	    clean dist-clean wiped-clean \
	    help sync update delete-proj \
	    install-aws-cli \
	    index-html upload-index-html

  values: check
	    @printf "$${BLUE}Values...$${CLEAR}\n"
	    @echo TEMPLATE:	$(TEMPLATE)
	    @echo EDITOR:	$(EDITOR)
	    @echo USER:		$(USER)
	    @echo PWD:		$(PWD)
	    @echo ORG:		$(ORG)
	    @echo TEXI:		$(TEXI)
	    @echo INFO:		$(INFO)
	    @ECHO INFOTN:	$(INFOTN)
	    @echo BUCKET:	$(BUCKET)
	    @echo PROJ:		$(PROJ) $S
	    @echo S3_BUCKET:	$(S3_BUCKET)
	    @echo HTTP_S:	$(HTTP_S)
	    @echo HTTPS_BUCKET:	$(HTTPS_BUCKET)
	    @echo VERS:		$(VERS)
	    @echo S3PROJ:	$(S3PROJ)
	    @echo S3VERS:	$(S3VERS)
	    @echo DIR:		$(DIR)
	    @echo DIR_OLD:	$(DIR_OLD)
	    @echo SRC:		$(SRC)
	    @echo DST_OLD:	$(DST_OLD)
	    @echo DST_NEW:	$(DST_NEW)
	    @echo PROJ_LIST:	"$(PROJ_LIST)"
	    @echo PROJINS3:	$(PROJINS3)

  check:
	    @printf "$${BLUE}Checking dependencies...$${CLEAR}\n"

	    @[[ -z $(BUCKET) ]] && \
	       { printf "$${RED}$(BUCKET) $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	       printf "$${CYAN}BUCKET: $${GREEN}$(BUCKET)$${CLEAR}\n";

	    @[[ -z $${GITHUB_TOKEN} ]] && \
	       { printf "$${RED}GITHUB_TOKEN $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	       printf "$${CYAN}GITHUB_TOKEN: $${GREEN}SET$${CLEAR}\n";

	    @[[ (-d ~/.aws) && (-f ~/.aws/credentials) && (-f ~/.aws/config) ]] && \
	       printf "$${CYAN}AWS credentials and config: $${GREEN}SET$${CLEAR}\n" || \
	       { printf "$${RED}~/.aws 'credentials' and 'config' must be set.$${CLEAR}\n"; exit 1; }

	    @[[ "$(shell $(EDITOR) --eval '(member (quote texinfo) org-export-backends)')" = "(texinfo)" ]] && \
		  printf "$${CYAN}Texinfo backend: $${GREEN}INSTALLED.$${CLEAR}\n" || \
		  { printf "$${YELLOW}Texinfo backend:$${CLEAR} $${RED}NOT INSTALLED; it must be installed.$${CLEAR}\n"; exit 1; }

	    @[[ $(shell $(EDITOR) --eval '(symbol-value org-confirm-babel-evaluate)') == "t" ]] && \
		  { printf "$${YELLOW}org-confirm-babel-evaluate:$${CLEAR} $${RED}T; set to NIL.$${CLEAR}\n"; exit 1; } || \
		  printf "$${CYAN}org-confirm-babel-evaluate: $${GREEN}OFF.$${CLEAR}\n\n"

  open-org: $(ORG)
	    @$(EDITOR) -n $(ORG)
  $(ORG):
	    @echo 'THERE IS NO $(ORG) FILE!!!'
	    exit 1

  texi: $(TEXI)
  $(TEXI): $(ORG)
	   @echo Making TEXI...
	   @$(EDITOR) -u --eval \
		  "(with-current-buffer (find-file-noselect \"$(ORG)\" t) \
			  (save-excursion \
			  (org-texinfo-export-to-texinfo)))"
	   @echo Done making TEXI.
  open-texi: texi
	   @$(EDITOR) -n $(TEXI)

  info: $(INFO)
  $(INFO): $(TEXI)
	   @echo Making INFO...
	   @makeinfo -o $(INFO) $(TEXI)
	   @$(EDITOR) -u -eval \
		  "(when (get-buffer \"$(INFO)\") \
			  (with-current-buffer (get-buffer \"$(INFO)\") \
				  (revert-buffer t t t)))"
	   @echo Done making INFO.

  open-info: info
	   @$(EDITOR) -u -eval \
		  "(if (get-buffer \"*info*\") \
			  (with-current-buffer (get-buffer \"*info*\") \
				(when (not (string= \"(symbol-value (quote Info-current-file))\" \"$(INFOTN)\")) \
					(info \"$(INFOTN)\")) \
				(revert-buffer t t t)) \
		      (info \"$(INFOTN)\"))"

  html: $(HTML)
  $(HTML): $(TEXI)
	   @echo Making HTML INFO..
	   @makeinfo --html -o $(DIR) $(TEXI)
	   @echo Done making HTML.
	   $(CMPRPL) $(DIR) $(DIR_OLD)
  open-html: html
	   @open $(HTML)

  # If pdftexi2dvi produces an error, it may still produce a viable PDF;
  # therefore, use --tidy.  If it produces an error, try to link the PDF;
  # if it does not produce an error, the PDF will be added to the top dir
  # and there will be no attempt to link.
  pdf:	$(PDF)
  $(PDF): $(TEXI)
	  @echo Making PDF INFO...
	  @-pdftexi2dvi --quiet --build=tidy $(TEXI) || ln -s $(PROJ).t2d/pdf/build/$(PDF) $(PDF)
	  @echo Done making PDF.
  open-pdf:pdf
	   @open $(PDF)

  sync:   $(HTML)
	  @echo Syncing version $(VERS) onto $(S3VERS)...
	  $(S3SYNC)
	  $(S3IMAGESYNC)
	  @echo Done syncing.
	  [[ $(VERS) != $(S3VERS) ]] && { echo Moving...; $(S3MOVE); echo Done moving.;  make homepage; } || :
	  [[ $(PROJINS3) = "NO" ]] && make homepage || :

  # This is a target-specific variable for updating the “description”
  # key on the GitHub repo page with the current version number.  It
  # first makes a curl call to the GitHub project repo, finds the
  # “description” line, pulls out the description only (leaving the old
  # version) and then prints the value with the current version number.
  # This value is used by the “homepage:” target in the PATCH call.
  # This method is arguably harder to code but faster to run than using
  # Perl with the JSON::PP module.

  homepage: description = $(shell \
	  curl -s \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S | \
		  (perl -ne 'if (/^\s*\"description\":\s*\"(.*): v(?:(?:[[:digit:]]+[.]?){3})/) {print $$1}'))

  ### NOTE the use of the S variable at the end of PROJ; this is to handle
  # the singular case of the GitHub repo using the plural form, Templates
  # whereas the the Template.org file uses the singular form.
  homepage: $(ORG) upload-index-html
	    @echo Updating homepage...
	    @echo DESCRIPTION: $(description)
	    @echo VERS: $(VERS)
	    @curl -i \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  -H "Content-Type: application/json" \
		  -X PATCH \
		  -d "{\"homepage\":\"$(HTTPS_BUCKET)/$(DIR)-$(VERS)\",\
		       \"description\":\"$(description): $(VERS)\"}" \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S
	    @echo Done updating homepage.

  delete-proj:
	  @echo Deleting project $(PROJ)...
	  @curl -i \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  -H "Accept: application/vnd.github.v3+json" \
		  -X DELETE \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S
	  @$(S3REMOVE)
	  @make dist-clean
	  @make upload-index-html
	  @$(EDITOR) -u --eval "(kill-buffer \"$(ORG)\")"
	  @rm -rf "../$(PROJ)"
	  @echo Done deleting project.

  index-html: $(INDEX)
  $(INDEX): $(ORG)
	  @echo making index.html...
	  $(EDITOR) --eval \
	  "(with-current-buffer (find-file-noselect \"$(ORG)\") \
		  (save-excursion \
		    (org-link-search \"#project-index-title\") \
		    (org-export-to-file (quote html) \"index.html\" nil t)))"
	  @echo Done making index.html.

  upload-index-html: $(INDEX)
	   @echo Uploading index.html...
	   $(S3COPY)
	   @echo Done uploading index.html

  install-aws-cli:
	    curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg" && \
	    sudo installer -pkg AWSCLIV2.pkg -target / && \
	    which aws && aws --version
	    rm -rf AWSCLIV2.pkg

  clean:
	  @echo Cleaning...
	    -@rm *~ 2>/dev/null
	    -@for file in *.??*; \
	    do \
		    ext=$${file#$(PROJ).}; \
		    [[ ! $${ext} =~ org|texi|info|pdf|html ]] && rm -rv $${file}; \
	    done

  dist-clean: clean
	  @echo Dist Cleaning...
	    @${EDITOR} -u --eval \
	      "(kill-buffer \"$(ORG)\")"
	    -@rm -rf *.{texi*,info*,html*,pdf*} $(DIR) $(TOOLS)
	    -@for dir in *; \
		do \
		    [ -d $$dir -a $$dir != "$(DIR_OLD)" -a $$dir != $(SAVE) ] && \
		    rm -vr $$dir; \
		done

  wipe-clean: dist-clean
	  @echo Wipe Clean...
	    -@rm -rf Makefile Readme.md $(DIR_OLD)
	    @git checkout Makefile README.md

  git-ready: dist-clean
	    git checkout Makefile
	    git checkout README.md
	    git status

  help:
	    @echo '"make boot" tangles all of the files in Template'
	    @echo '"make default" makes the .texi file, the .info file, \
	    the html files, and the .pdf file.'
	    @echo

	    @echo '"make check" checks for prerequistes'
	    @echo '"make values" runs check and prints variable values'
	    @echo

	    @echo '"make texi" makes the .texi file'
	    @echo '"make info" makes the .info file'
	    @echo '"make html" makes the html distribution in a subdirectory'
	    @echo '"make pdf" makes the .pdf file'
	    @echo

	    @echo '"make open-org" opens the ORG program using emacsclient for editing'
	    @echo '"make open-texi" opens the .texi file using emacsclient for review'
	    @echo '"make open-html" opens the distribution index.html file \
	    in the default web browser'
	    @echo '"make open-pdf" opens the .pdf file'
	    @echo

	    @echo '"make sync" syncs the html files in the AWS S3 bucket BUCKET; \
	    you must have your AWS S3 bucket name in the env var AWS_S3_BUCKET; \
	    You must have your AWS credentials installed in ~/.aws/credentials'
	    @echo

	    @echo '"make install-aws-cli" installs the "aws cli v2" command-line tools'
	    @echo 'You also need to run "aws configure" and supply your Access Key and Secret Access Key'
	    @echo

	    @echo '"make clean" removes the .texi, .info, and backup files ("*~")'
	    @echo '"make dist-clean" cleans, removes the html distribution, \
	    and removes the build directory'
	    @echo '"make wipe-clean" wipes clean the directory, including old directories'
	    @echo

	    @echo '"make delete-proj" deletes the project from the file system, GitHub and AWS'

#+end_src

*** TODO Next
1. The CloudFront configuration needs to be updated recognize the new version
   directory that is created as part of the ~sync~ operation.

2. Update the GitHub HOME website link for each new sync operation.

3. Store on GitHub a version of each other format upon a sync operation (i.e.,
   the INFO and PDF versions)

** Compare Replace

#+begin_comment
The following source code tangles all files during an export operation. This is
to  make  sure  the  ~cmprpl~  source code  exists  in  the  ~resources/tools/~
directory before running  the Makefile target =html=. It also  makes sure there
is a Makefile on an initial export. The following code is not exported.
#+end_comment

#+name:tangle-org-file
#+header: :exports results :eval yes :results silent
#+begin_src emacs-lisp
(org-babel-tangle-file (buffer-file-name))
#+end_src

The  AWS ~sync~  command  relies  upon time  stamps  to  determine whether  two
programs are identical or not, as  well as content.  If two otherwise identical
files have  different time stamps,  ~sync~ will  assume they are  different and
will  process the  newer.   However, the  ~texinfo~  ~makeinfo --html~  command
produces all  new files even  if some files  (or most files)  remain unchanged.
This  means that  all files  will be  uploaded to  the AWS  S3 bucket  on every
iteration, even though the majority of the files are actually unchanged.

The ~cmprpl~  source code attempts to  resolve the issue of  identical exported
code having different  time stamps, thus defeating the benefit  provided by the
~aws2 s3 sync~ command uploading only changed files.

This program makes sure that a generated HTML directory exists: =$DIR_NEW=.  If
it doesn’t, then it is in an improper state and the program stops with an error
message.

The  program then  checks  if  an old  directory  exists,  =$DIR_OLD=.  If  one
doesn’t,  then one  is  created by  copying the  current  new directory.   This
provides a baseline  for comparisons going forward.  The program  exits at that
point. It is very important that  the =$DIR_OLD= directory not be deleted going
forward.

Given  that =$DIR_OLD=  exists, the  program then  loops through  all files  in
=$DIR_NEW= and  compares them  to the  files in =$DIR_OLD=.   If the  files are
identical, the =$DIR_OLD= file replaces the =$DIR_NEW= file while retaining the
old time stamp (using the ~-p~ option of ~cp~. If a file is different, then the
=$DIR_NEW= file  replaces the =$DIR_OLD=  file, thus giving it  updated content
and  an updated  time stamp.   If the  file does  not exist  in the  =$DIR_OLD=
directory, then it is added.

The  program then  loops through  all of  the files  in the  old directory  and
deletes  any that  do not  exist in  the new  directory.  Now  both directories
should be in sync.

#+caption:Compare Replace program
#+name:cmprpl
#+header: :mkdirp t
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src sh :tangle resources/tools/cmprpl
  [[ $# -eq 2 ]] || { echo "ERROR: Incorrect command line arguments"; exit 1; }
  DIR_NEW=$1
  DIR_OLD=$2

  [[ -d $DIR_NEW ]] || { echo "ERROR: $DIR_NEW does not exist"; exit 1; }
  [[ -d $DIR_OLD ]] || { echo "CREATING: $DIR_OLD does not exist"; cp -a $DIR_NEW $DIR_OLD; exit 0; }

  for newfile in $DIR_NEW/*
  do
      oldfile=$DIR_OLD/$(basename $newfile)
      if [[ -e $oldfile ]]
      then
	 if cmp -s $newfile $oldfile
	 then
	     printf "${GREEN}copying OLD to NEW${CLEAR}: "
	     cp -vp $oldfile $newfile
	 else
	     printf "${PURPLE}copying NEW to OLD${CLEAR}: "
	     cp -vp $newfile $oldfile
	 fi
      else
	  printf "${BLUE}creating NEW in OLD${CLEAR}: "
	  cp -vp $newfile $oldfile
      fi
  done

  for oldfile in $DIR_OLD/*
  do
      newfile=$DIR_NEW/$(basename $oldfile)
      if [[ ! -e $newfile ]]
      then
	  printf "${RED}removing OLD${CLEAR}: "
	  rm -v $oldfile
      fi
  done
#+end_src


** Update Utility Commands
*** Get Parsed Org Tree
This function looks for an Org file in the present working directory, and if it
finds one returns  a parsed tree using  ~org-element-parse-buffer~.  It returns
=nil= if there is no Org file or if the found file is not in ~org-mode~.

#+name:get-parsed-org-tree
#+header: :results silent
#+begin_src emacs-lisp
(defun get-parsed-org-tree (&optional org-dir)
  "This function takes an optional directory name, changes to
that directory if given, otherwise uses the pwd, and finds an Org
file and returns its parsed tree, or nil if none found."
  (when org-dir
      (cd (file-name-as-directory org-dir)))
  (let ((buf (car-safe (find-file-noselect "*.org" nil nil t))))
    (if buf
	(with-current-buffer buf (org-element-parse-buffer))
      nil)))
#+end_src

*** Check for CID
This code  checks whether an  Org file contains  a =custom_id= of  a particular
value.  It accepts  a ~cid-value~ and an optional directory.   If the directory
is not given, then it defaults to the current directory.  If throws an error if
the directory does not exist.  It returns =nil= if the given directory does not
contain an Org file.   It returns =t= if the Org file  contains a node property
of   =custom_id=  and   value  ~cid-value~,   or   =nil=  if   not.   It   uses
~get-parsed-org-tree~.

#+name:org-tree-cid-p
#+header: :results silent
#+begin_src emacs-lisp
(defun org-tree-cid-p (cid-value &optional org-dir)
  "Check whether an org file contains a custom_id of CID"
  (let ((tree (get-parsed-org-tree org-dir)))
    (car (org-element-map tree 'property-drawer
	   (lambda (pd) (org-element-map (org-element-contents pd) 'node-property
			  (lambda (np)
			    (and
			     (string= "custom_id" (org-element-property :key np))
			     (string= cid-value (org-element-property :value np))))))
	   nil t))))
#+end_src

#+name:run-org-tree-cid-p
#+header: :var cid="build-tools"
#+header: :var dir="/usr/local/dev/programming/MasteringEmacs"
#+header: :var gpot=get-parsed-org-tree()
#+header: :var otcp=org-tree-cid-p()
#+header: :results value
#+header: :eval never-export
#+begin_src emacs-lisp
(org-tree-cid-p cid dir)
#+end_src

#+call: run-org-tree-cid-p(dir="/usr/local/dev/programming/MasteringEmacs")

** Bucket Index HTML
The bucket should contain a master ~index.html~  file that links to each of the
individual project  ~index.html~ files.  The  master ~index.html~ file  will be
placed at the root of  the bucket, ~https://<bucket-name>.com/~, and the bucket
must be set up to serve this ~index.html~ when the user hits the root.

*** Get Bucket Name
 This  code searches  for  the keyword-value  pair =bucket:<BUCKET-NAME>=  that
 should be  located towards the  beginning of the  file, and returns  the value
 =BUCKET-NAME= or nil if not found.

#+name: get-bucket-name
#+header: :results value
#+begin_src emacs-lisp
   (save-excursion
     (goto-char (point-min))
     (re-search-forward "^#\\+bucket:\\s*?\\(.*\\)$" nil t)
     (match-string-no-properties 1))
#+end_src

For some reason, ~get-bucket-name~ does not  work when called from the headline
[[#project-index-links][=Links for  bucket=]] below  when creating  =index.html=, even  if it  returns as
~(prin1 ...)~ and is  set up to ~:return output~; the  call receives =nil=. The
following code from ~bucket-name~, however, works. I don't know why.

#+name: bucket-name
#+header: :results output
#+header: :var bucket-name=get-bucket-name()
#+begin_src emacs-lisp
(prin1 bucket-name)
#+end_src

*** Bucket HTTPS URL
This  code calls  ~get-bucket-name~ and  returns the  value returned  as a  URL
string or nil.

#+name: bucket-https-url
#+header: :results value
#+header: :var b=get-bucket-name()
#+begin_src emacs-lisp
(concat "https://" b)
#+end_src

*** S3 Bucket URL
This code calls ~get-bucket-name~ and returns the AWS S3 bucket url.

#+name: s3-bucket-url
#+header: :results value
#+header: :var b=get-bucket-name()
#+begin_src emacs-lisp
(concat "s3://" b)
#+end_src

*** Bucket Projects List
This code uses the ~s3-bucket-url~ result to obtain the list of projects in the
bucket.  It does  this by calling the  AWS S3 high-level command  ~ls~ and then
removing the  =PRE= string in  each result.  The result  that is returned  is a
single  string that  can be  separated into  individual links  by breaking  the
string on spaces.

#+name: bucket-projects-list
#+header: :results output
#+header: :var bucket=s3-bucket-url()
#+begin_src sh
/usr/local/bin/aws s3 ls ${bucket} | sed -ne 's/^.*PRE //p'
#+end_src

*** Bucket Project Links
This code  uses the result  from ~bucket-projects-list~ to create  an unordered
list of  links written to  bucket projects, written  in Org-mode syntax.  It is
executed by a =#+call:= in [[*Bucket Index][*Bucket  Index]] during an HTML export of that subtree
to a file called =index.html=.

#+name: bucket-project-links
#+header: :var b-url=bucket-https-url()
#+header: :var projects=bucket-projects-list()
#+header: :results output raw
#+begin_src emacs-lisp
(seq-do (lambda (u) (princ (format "- [[%s/%sindex.html][~%s~]]
" b-url u u))) (split-string projects))
#+end_src

*** Bucket Index
    :PROPERTIES:
    :custom_id: project-index-title
    :export_file_name: index.html
    :export_subtitle: {{{version}}} created {{{upload-date}}}
    :END:
#+html_doctype: html5
#+options: toc:nil html5-fancy:t

#+html: <hr>

**** Links for bucket call_bucket-name()
     :PROPERTIES:
     :unnumbered: t
     :custom_id: project-index-links
     :END:

#+call: bucket-project-links()
** Project Readme
This adds the README.md template to a project. It should be customized uniquely
for the project.

#+name:project-readme
#+header: :tangle README.md
#+begin_src markdown
# TITLE
## Subtitle
## Author
## Date
## Version
# ABSTRACT
This is the Org Template file.	It is the parent of all other Org Info blogs,
and provides the source code for processing them in various different ways.
# INTRODUCTION
# CHAPTER
## Section
### Subsection
#+end_src

** Boot Template
:PROPERTIES:
:dependency1: EMACS:=:/Applications/MacPorts/Emacs.app/Contents/MacOS/Emacs or similar
:dependency2: EDITOR:=:emacsclient
:dependency3: =SYNC_ORG_TEMPLATE= defined as $DEV/Templates/Org/Template.org
:END:
Although running the command ~org-babel-tangle~ (=C-c C-v t=) from within Emacs
will install  everything, it would  be nice to have  a simple Makefile  that is
downloaded with this  file that could be  invoked to do the  same thing without
starting Emacs and Org-mode and keying in the ~org-babel-tangle~ command.  This
little Makefile should be stored on  GitHub along with the ~Template.org~ file.
When  the source  is extracted  to a  directory, then  running this  Makefile's
default rule  as simply ~make~  will extract the ~preprocess.el~  script, which
updates  =DEV= and  then  extracts the  full Makefile.   Because  this file  is
tangled along with the full Makefile, it simply gets tacked onto the end of the
big Makefile as an additional rule.   Now, running ~make~ runs the default rule
from the  main Makefile, which is  to extract everything, then  export to TEXI,
INFO, HTML, and PDF forms.

It is assumed that an Emacs server is running, and that the $EDITOR environment
variable is set to use ~emacsclient~.

#+name:boot-template
#+header: :tangle Makefile
#+begin_src makefile
  boot:
	  $(EDITOR) -u --eval \
		  "(with-current-buffer (car (find-file-noselect \"./*.org\" nil nil t)) \
			  (goto-char (point-min)) \
			  (re-search-forward \"^#[+]name:preprocess.el$$\") \
			  (org-babel-tangle (quote (4))) \
			  (save-buffer) \
			  (kill-buffer))" \
	  --eval \
		  "(let ((rsrcdir \"resources\") \
			 (subdirs (list \"tools\" \"images\"))) \
		     (mkdir rsrcdir t) \
		     (dolist (subdir subdirs) (mkdir (concat rsrcdir \"/\" subdir) t)))"
	  ./resources/tools/preprocess.el
#+end_src

** Preprocess Env Vars
The environment variable DEV can be  in different locations and will be spelled
differently based  on how the  local machine is set  up.  For instance,  on one
system,  it will  be at  ~$HOME/Dev~  while in  another  system it  will be  at
~/usr/local/dev~.  However, the =:tangle= keyword  does not expand variables in
the form ~${DEV}~,  but rather requires absolute  paths, like ~/usr/local/dev~.
Therefore, this program works like a preprocessor for environment variables set
up  as part  of  =:tangle= lines,  changing them  to  their system  environment
variable values prior to tangling.  It lives in the ~resources/tools~ directory.

#+name:preprocess.el
#+header: :mkdirp t
#+header: :tangle resources/tools/preprocess.el
#+header: :shebang "#!/opt/local/bin/emacs -Q --script"
#+begin_src emacs-lisp
  (with-current-buffer (car (find-file-noselect "./*.org" nil nil t))
    (save-excursion
    (goto-char (point-min))
    (let ((re-search-str "\\(?::tangle\\|load-file \\(?:[\\]*\\)?[\"]\\)\s*\\(.*?/[dD]ev\\)/")
          (dev (getenv "DEV")))
      (while
              (re-search-forward re-search-str nil t)
              (replace-match dev t nil nil 1)))
    (save-buffer)
    (require 'org)
    (org-babel-tangle)))
#+end_src

** Samples
#+begin_comment
(cd "~/Dev/Emacs/MasteringEmacs/")
"/Users/pine/Dev/Emacs/MasteringEmacs/"

(defun add-bucket (org bucket)
  "Add a bucket keyword BUCKET to the org file ORG."
  (interactive "fFile: \nsBUCKET: ")
  (with-current-buffer (find-file-noselect org)
    (let* ((tree (org-element-parse-buffer))
	   (ins (car (org-element-map tree (quote section)
		 (lambda (s)
		   (org-element-map s (quote keyword)
		     (lambda (kw) (when (equal "MACRO" (org-element-property :key kw)) (1- (org-element-property :end kw))))
		     nil nil :keyword))
		 nil t nil nil))))
      (goto-char ins)
      (insert (format "#+bucket:%s\n" bucket))
      ())))

(add-bucket "MasteringEmacs.org" "pinecone-forest")
nil

(defun hl-region (raw-hl)
  "Obtain the begin and end positions for a headline."
  (with-current-buffer (find-file-noselect (getenv "SYNC_ORG_TEMPLATE"))
    (let* ((tree (get-parsed-tree))
	   (hl (car-safe (org-element-map tree 'headline
			   (lambda (hl) (when
					    (string= raw-hl
						     (org-element-property :raw-value hl))
					  (org-element-context)))
			   nil nil t))))
      (cons
       (org-element-property :begin hl)
       (org-element-property :end hl))
      )))

(hl-region "Build Tools")

(4888 . 29646)

(defun get-hl-with-prop (org-dir hl-prop)
  "Given a directory containing an Org template file and a custom_id property name, return the headline containing that custom_id, or nil if none."
  (progn
    (cd org-dir)
    (let ((org-buf (car-safe (find-file-noselect "*.org" nil nil t))))
      (if org-buf
	  (with-current-buffer org-buf
	    (let ((tree (org-element-parse-buffer)))
	      (org-element-map tree 'headline
		(lambda (hl)
		  (let ((cid (org-element-property :CUSTOM_ID hl)))
		    (when (string= hl-prop cid)
		      (and
		       (message (format "Found the headline %s containing property %s." (org-element-property :raw-value hl) hl-prop))
		       hl))))
		nil t)))
	(and
	 (message (format "The directory %s does not contain an Org file." org-dir))
	 nil)))))

(get-hl-with-prop "~/Dev/Templates/Org" "build-tools")

(headline (:raw-value "Build Tools" :begin 4888 :end 29646 :pre-blank 0 :contents-begin 4902 :contents-end 29645 :level 1 :priority nil :tags nil :todo-keyword nil :todo-type nil :post-blank 1 :footnote-section-p nil :archivedp nil :commentedp nil :post-affiliated 4888 :FROM-FILE "Template" :CUSTOM_ID "build-tools" :APPENDIX "t" :title "Build Tools"))









;;; Add a keyword named 'bucket' just after the version macro.
;;; This function should be run from within the directory containing the Org file.
(defun add-bucket (org-file s3-bucket)
  "Add the name of the associated AWS S3 bucket to an Org templated file."
  (with-current-buffer (find-file-noselect org-file)
    (goto-char (point-min))
    (let* ((tree (org-element-parse-buffer))
	   ;; find the beginning position of the first headline to act as a limit
	   (hl1 (org-element-map tree (quote headline) (lambda (hl) (org-element-property :begin hl)) nil t)))
      ;; Check for the presence of a bucket keyword before the first headline
      (unless (re-search-forward "^#\\+bucket:" hl1 t)
	;; If no bucket keyword is found, search for a keyword MACRO with the value 'version'
	(org-element-map tree (quote keyword)
	  (lambda (kw) (when (and (string= "MACRO" (org-element-property :key kw))
				  (string-match-p "version" (org-element-property :value kw)))
			 ;; return the end position of the MACRO; subtract an empty line if there is one
			 (goto-char (- (org-element-property :end kw) (org-element-property :post-blank kw)))
			 (insert "#+bucket:" s3-bucket)
			 (newline)
			 (basic-save-buffer)
			 (message (format "Added bucket %s" s3-bucket))))
	  nil t)))))

(add-bucket "MasteringEmacs.org" "pinecone-forest.com")
nil

"Added bucket pinecone-forest.com"









(keyword (:key "MACRO" :value "version Version 0.0.108" :begin 148 :end 181 :post-blank 1 :post-affiliated 148 ...))
("TITLE" "SUBTITLE" "AUTHOR" "DATE" "MACRO" "TEXINFO" "TEXINFO" "CINDEX" "CINDEX" "CINDEX" "CINDEX" "CINDEX" ...)







((keyword (:key "MACRO" :value "version Version 0.0.107" :begin 148 :end 181 :post-blank 1 :post-affiliated 148 ...)))
#+end_comment

* List of Programs
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Listing

* List of Examples
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Example

* Copying
:PROPERTIES:
:copying:  t
:END:

Copyright \copy 2020 by {{{author}}}

* Concept Index
:PROPERTIES:
:index: cp
:appendix: yes
:END:

* Program Index
:PROPERTIES:
:index: pg
:appendix: yes
:END:

* Function Index
:PROPERTIES:
:index: fn
:appendix: yes
:END:

* Variable Index
:PROPERTIES:
:index: vr
:appendix: yes
:END:


* Configuration							   :noexport:
#+startup:content

#+todo: SOMEDAY(s@) TODO(t@) INPROGRESS(i@) WAIT(w@) | CANCEL(c@) DONE(d!)

#+options: H:4

#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+texinfo_dir_category:<DIR CATEGORY>
#+texinfo_dir_title:<DIR TITLE>
#+texinfo_dir_desc:<DIR DESCRIPTION>
#+texinfo_printed_title:JavaScriptCoreLanguage---JavaScript Core Language Path


* Footnotes

[fn:1]In the browser, add =index.text= to the end of the URL to see the source.

[fn:2]Markdown requires the standard Perl library module Digest::MD5.


* Local Variables						   :noexport:
# Local Variables:
# fill-column: 79
# indent-tabs-mode: t
# eval: (auto-fill-mode)
# time-stamp-pattern: "8/^\\#\\+date:%:y-%02m-%02d %02H:%02M$"
# End:
